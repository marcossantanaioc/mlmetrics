---

title: Title


keywords: fastai
sidebar: home_sidebar



nb_path: "metrics.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: metrics.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="sklm_to_scorer" class="doc_header"><code>sklm_to_scorer</code><a href="https://github.com/marcossantanaioc/mlmetrics/tree/master/mlmetrics/metrics.py#L12" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>sklm_to_scorer</code>(<strong><code>func</code></strong>, <strong><code>transform</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Converts func into sklearn scorer</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="R2Score" class="doc_header"><code>R2Score</code><a href="https://github.com/marcossantanaioc/mlmetrics/tree/master/mlmetrics/metrics.py#L17" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>R2Score</code>(<strong><code>y_true</code></strong>=<em><code>None</code></em>, <strong><code>y_pred</code></strong>=<em><code>None</code></em>, <strong><code>sample_weight</code></strong>=<em><code>None</code></em>, <strong><code>multioutput</code></strong>:<code>str</code>=<em><code>'uniform_average'</code></em>, <strong><code>transform</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>:math:<code>R^2</code> (coefficient of determination) regression score function.</p>
<p>Arguments</p>
<p>y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Ground truth (correct) target values.</p>
<p>y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Estimated target values.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.</p>
<p>multioutput : {'raw_values', 'uniform_average', 'variance_weighted'},             array-like of shape (n_outputs,) or None, default='uniform_average'
    Defines aggregating of multiple output scores.
    Array-like value defines weights used to average scores.
    Default is "uniform_average".
    'raw_values' :
        Returns a full set of scores in case of multioutput input.
    'uniform_average' :
        Scores of all outputs are averaged with uniform weight.
    'variance_weighted' :
        Scores of all outputs are averaged, weighted by the variances
        of each individual output.
    .. versionchanged:: 0.19
        Default value of multioutput is 'uniform_average'.</p>
<p>Returns:
    r2 : float
        The  score :math:<code>R^2</code> or ndarray of scores if ‘multioutput’ is ‘raw_values’.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="MSEScore" class="doc_header"><code>MSEScore</code><a href="https://github.com/marcossantanaioc/mlmetrics/tree/master/mlmetrics/metrics.py#L59" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>MSEScore</code>(<strong><code>y_true</code></strong>=<em><code>None</code></em>, <strong><code>y_pred</code></strong>=<em><code>None</code></em>, <strong><code>sample_weight</code></strong>=<em><code>None</code></em>, <strong><code>multioutput</code></strong>:<code>str</code>=<em><code>'uniform_average'</code></em>, <strong><code>squared</code></strong>=<em><code>True</code></em>, <strong><code>transform</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Mean squared error regression loss.</p>
<p>Arguments</p>
<p>y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Ground truth (correct) target values.</p>
<p>y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Estimated target values.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.</p>
<p>multioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'
    Defines aggregating of multiple output values.
    Array-like value defines weights used to average errors.
    'raw_values' :
        Returns a full set of errors in case of multioutput input.
    'uniform_average' :
        Errors of all outputs are averaged with uniform weight.</p>
<p>Returns:
    mse : float
         If True returns MSE value, if False returns RMSE value.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="MAEScore" class="doc_header"><code>MAEScore</code><a href="https://github.com/marcossantanaioc/mlmetrics/tree/master/mlmetrics/metrics.py#L94" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>MAEScore</code>(<strong><code>y_true</code></strong>=<em><code>None</code></em>, <strong><code>y_pred</code></strong>=<em><code>None</code></em>, <strong><code>sample_weight</code></strong>=<em><code>None</code></em>, <strong><code>multioutput</code></strong>:<code>str</code>=<em><code>'uniform_average'</code></em>, <strong><code>transform</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Mean absolute error regression loss.</p>
<p>Arguments</p>
<p>y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Ground truth (correct) target values.</p>
<p>y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Estimated target values.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.</p>
<p>multioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'
    Defines aggregating of multiple output values.
    Array-like value defines weights used to average errors.
    'raw_values' :
        Returns a full set of errors in case of multioutput input.
    'uniform_average' :
        Errors of all outputs are averaged with uniform weight.</p>
<p>Returns:
    mae : float
         returns MAE.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="BalancedAccuracyScore" class="doc_header"><code>BalancedAccuracyScore</code><a href="https://github.com/marcossantanaioc/mlmetrics/tree/master/mlmetrics/metrics.py#L129" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>BalancedAccuracyScore</code>(<strong><code>y_true</code></strong>=<em><code>None</code></em>, <strong><code>y_pred</code></strong>=<em><code>None</code></em>, <strong><code>sample_weight</code></strong>=<em><code>None</code></em>, <strong><code>adjusted</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>transform</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Computes Matthew's correlation coefficient between actual and predicted values.
Arguments</p>

<pre><code>y_true : array-like
    Ground truth (correct) target values.

y_pred : array-like
    Estimated targets as returned by a classifier.

sample_weight : array-like, default=None
    Sample weights.

adjusted : bool, default=False
    When true, the result is adjusted for chance, so that random performance would score 0, while keeping perfect performance at a score of 1.


</code></pre>
<p>Returns:
    balanced_accuracy : float
        Balanced accuracy score.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="MatthewsCorrCoef" class="doc_header"><code>MatthewsCorrCoef</code><a href="https://github.com/marcossantanaioc/mlmetrics/tree/master/mlmetrics/metrics.py#L158" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>MatthewsCorrCoef</code>(<strong><code>y_true</code></strong>=<em><code>None</code></em>, <strong><code>y_pred</code></strong>=<em><code>None</code></em>, <strong><code>sample_weight</code></strong>=<em><code>None</code></em>, <strong><code>transform</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Computes Matthew's correlation coefficient between actual and predicted values.
Arguments</p>

<pre><code>y_true : array-like
    Ground truth (correct) target values.

y_pred : array-like
    Estimated targets as returned by a classifier.

sample_weight : array-like
    Sample weights.


</code></pre>
<p>Returns:
    mcc : float
    The Matthews correlation coefficient (+1 represents a perfect prediction, 0 an average random prediction and -1 and inverse prediction).</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="PrecisionScore" class="doc_header"><code>PrecisionScore</code><a href="https://github.com/marcossantanaioc/mlmetrics/tree/master/mlmetrics/metrics.py#L184" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>PrecisionScore</code>(<strong><code>y_true</code></strong>=<em><code>None</code></em>, <strong><code>y_pred</code></strong>=<em><code>None</code></em>, <strong><code>average</code></strong>:<code>str</code>=<em><code>'binary'</code></em>, <strong><code>pos_label</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>sample_weight</code></strong>=<em><code>None</code></em>, <strong><code>transform</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Computes Precision between actual and predicted values
Arguments</p>

<pre><code>y_true : array-like
    Ground truth (correct) target values.

y_pred : array-like
    Estimated targets as returned by a classifier.


average : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None, default='binary'

    This parameter is required for multiclass/multilabel targets.
    If ``None``, the scores for each class are returned. Otherwise, this
    determines the type of averaging performed on the data:
    ``'binary'``:
        Only report results for the class specified by ``pos_label``.
        This is applicable only if targets (``y_{true,pred}``) are binary.
    ``'micro'``:
        Calculate metrics globally by counting the total true positives,
        false negatives and false positives.
    ``'macro'``:
        Calculate metrics for each label, and find their unweighted
        mean.  This does not take label imbalance into account.
    ``'weighted'``:
        Calculate metrics for each label, and find their average weighted
        by support (the number of true instances for each label). This
        alters 'macro' to account for label imbalance; it can result in an
        F-score that is not between precision and recall.
    ``'samples'``:
        Calculate metrics for each instance, and find their average (only
        meaningful for multilabel classification where this differs from
        :func:`accuracy_score`).

sample_weight : array-like
    Sample weights.


</code></pre>
<p>Returns:
    precision : float (if average is not None) or array of float of shape (n_unique_labels,)
        Precision of the positive class in binary classification or weighted
        average of the precision of each class for the multiclass task.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="RecallScore" class="doc_header"><code>RecallScore</code><a href="https://github.com/marcossantanaioc/mlmetrics/tree/master/mlmetrics/metrics.py#L237" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>RecallScore</code>(<strong><code>y_true</code></strong>=<em><code>None</code></em>, <strong><code>y_pred</code></strong>=<em><code>None</code></em>, <strong><code>average</code></strong>:<code>str</code>=<em><code>'binary'</code></em>, <strong><code>pos_label</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>sample_weight</code></strong>=<em><code>None</code></em>, <strong><code>transform</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Computes Recall (Senstivity) between actual and predicted values
Arguments</p>

<pre><code>y_true : array-like
    Ground truth (correct) target values.

y_pred : array-like
    Estimated targets as returned by a classifier.


average : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None, default='binary'

    This parameter is required for multiclass/multilabel targets.
    If ``None``, the scores for each class are returned. Otherwise, this
    determines the type of averaging performed on the data:
    ``'binary'``:
        Only report results for the class specified by ``pos_label``.
        This is applicable only if targets (``y_{true,pred}``) are binary.
    ``'micro'``:
        Calculate metrics globally by counting the total true positives,
        false negatives and false positives.
    ``'macro'``:
        Calculate metrics for each label, and find their unweighted
        mean.  This does not take label imbalance into account.
    ``'weighted'``:
        Calculate metrics for each label, and find their average weighted
        by support (the number of true instances for each label). This
        alters 'macro' to account for label imbalance; it can result in an
        F-score that is not between precision and recall.
    ``'samples'``:
        Calculate metrics for each instance, and find their average (only
        meaningful for multilabel classification where this differs from
        :func:`accuracy_score`).

sample_weight : array-like
    Sample weights.


</code></pre>
<p>Returns:
    recall : float (if average is not None) or array of float of shape (n_unique_labels,)
        Recall of the positive class in binary classification or weighted
        average of the recall of each class for the multiclass task.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="FBetaScore" class="doc_header"><code>FBetaScore</code><a href="https://github.com/marcossantanaioc/mlmetrics/tree/master/mlmetrics/metrics.py#L290" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>FBetaScore</code>(<strong><code>y_true</code></strong>=<em><code>None</code></em>, <strong><code>y_pred</code></strong>=<em><code>None</code></em>, <strong><code>beta</code></strong>:<code>float</code>=<em><code>0.5</code></em>, <strong><code>pos_label</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>average</code></strong>:<code>str</code>=<em><code>'binary'</code></em>, <strong><code>sample_weight</code></strong>=<em><code>None</code></em>, <strong><code>transform</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Compute the F-beta score between actual and predicted values</p>

<pre><code>Arguments

</code></pre>
<p>y_true : array-like
    Ground truth (correct) target values.</p>
<p>y_pred : array-like
    Estimated targets as returned by a classifier.</p>
<p>average : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None, default='binary'</p>

<pre><code>This parameter is required for multiclass/multilabel targets.
If ``None``, the scores for each class are returned. Otherwise, this
determines the type of averaging performed on the data:
``'binary'``:
Only report results for the class specified by ``pos_label``.
This is applicable only if targets (``y_{true,pred}``) are binary.
``'micro'``:
Calculate metrics globally by counting the total true positives,
false negatives and false positives.
``'macro'``:
Calculate metrics for each label, and find their unweighted
mean.  This does not take label imbalance into account.
``'weighted'``:
Calculate metrics for each label, and find their average weighted
by support (the number of true instances for each label). This
alters 'macro' to account for label imbalance; it can result in an
F-score that is not between precision and recall.
``'samples'``:
Calculate metrics for each instance, and find their average (only
meaningful for multilabel classification where this differs from
:func:`accuracy_score`).

</code></pre>
<p>sample_weight : array-like
    Sample weights.</p>
<p>Returns:
    fbeta_score : float (if average is not None) or array of float, shape = [n_unique_labels]
    F-beta score of the positive class in binary classification or weighted average of the F-beta score of each class for the multiclass task.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ROCAucScore" class="doc_header"><code>ROCAucScore</code><a href="https://github.com/marcossantanaioc/mlmetrics/tree/master/mlmetrics/metrics.py#L341" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ROCAucScore</code>(<strong><code>y_true</code></strong>=<em><code>None</code></em>, <strong><code>y_score</code></strong>=<em><code>None</code></em>, <strong><code>average</code></strong>:<code>str</code>=<em><code>'macro'</code></em>, <strong><code>sample_weight</code></strong>=<em><code>None</code></em>, <strong><code>transform</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.
Arguments</p>
<p>y_true : array-like
    Ground truth (correct) target values.</p>
<p>y_score : array-like</p>

<pre><code>Target scores.
* In the binary case, it corresponds to an array of shape
  `(n_samples,)`. Both probability estimates and non-thresholded
  decision values can be provided. The probability estimates correspond
  to the **probability of the class with the greater label**,
  i.e. `estimator.classes_[1]` and thus
  `estimator.predict_proba(X, y)[:, 1]`. The decision values
  corresponds to the output of `estimator.decision_function(X, y)`.
  See more information in the :ref:`User guide &lt;roc_auc_binary&gt;`;
* In the multiclass case, it corresponds to an array of shape
  `(n_samples, n_classes)` of probability estimates provided by the
  `predict_proba` method. The probability estimates **must**
  sum to 1 across the possible classes. In addition, the order of the
  class scores must correspond to the order of ``labels``,
  if provided, or else to the numerical or lexicographical order of
  the labels in ``y_true``. See more information in the
  :ref:`User guide &lt;roc_auc_multiclass&gt;`;
* In the multilabel case, it corresponds to an array of shape
  `(n_samples, n_classes)`. Probability estimates are provided by the
  `predict_proba` method and the non-thresholded decision values by
  the `decision_function` method. The probability estimates correspond
  to the **probability of the class with the greater label for each
  output** of the classifier. See more information in the
  :ref:`User guide &lt;roc_auc_multilabel&gt;`.


</code></pre>
<p>average : {'micro', 'macro', 'samples', 'weighted'} or None,             default='macro'
    If <code>None</code>, the scores for each class are returned. Otherwise,
    this determines the type of averaging performed on the data:
    Note: multiclass ROC AUC currently only handles the 'macro' and
    'weighted' averages.
    <code>'micro'</code>:
        Calculate metrics globally by considering each element of the label
        indicator matrix as a label.
    <code>'macro'</code>:
        Calculate metrics for each label, and find their unweighted
        mean.  This does not take label imbalance into account.
    <code>'weighted'</code>:
        Calculate metrics for each label, and find their average, weighted
        by support (the number of true instances for each label).
    <code>'samples'</code>:
        Calculate metrics for each instance, and find their average.
    Will be ignored when <code>y_true</code> is binary.</p>
<p>sample_weight : array-like
    Sample weights.</p>
<p>Returns:
    auc : float
        Area under ROC for predicted classes</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="APScore" class="doc_header"><code>APScore</code><a href="https://github.com/marcossantanaioc/mlmetrics/tree/master/mlmetrics/metrics.py#L413" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>APScore</code>(<strong><code>y_true</code></strong>=<em><code>None</code></em>, <strong><code>y_score</code></strong>=<em><code>None</code></em>, <strong><code>average</code></strong>:<code>str</code>=<em><code>'macro'</code></em>, <strong><code>sample_weight</code></strong>=<em><code>None</code></em>, <strong><code>transform</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.
Arguments</p>
<p>y_true : array-like
    Ground truth (correct) target values.</p>
<p>y_score : array-like</p>

<pre><code>Target scores, can either be probability estimates of the positive
class, confidence values, or non-thresholded measure of decisions
(as returned by :term:`decision_function` on some classifiers).


</code></pre>
<p>average : {'micro', 'samples', 'weighted', 'macro'} or None,             default='macro'
    If <code>None</code>, the scores for each class are returned. Otherwise,
    this determines the type of averaging performed on the data:
    <code>'micro'</code>:
        Calculate metrics globally by considering each element of the label
        indicator matrix as a label.
    <code>'macro'</code>:
        Calculate metrics for each label, and find their unweighted
        mean.  This does not take label imbalance into account.
    <code>'weighted'</code>:
        Calculate metrics for each label, and find their average, weighted
        by support (the number of true instances for each label).
    <code>'samples'</code>:
        Calculate metrics for each instance, and find their average.
    Will be ignored when <code>y_true</code> is binary.</p>
<p>pos_label : int or str, default=1
    The label of the positive class. Only applied to binary <code>y_true</code>.
    For multilabel-indicator <code>y_true</code>, <code>pos_label</code> is fixed to 1.</p>
<p>sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.</p>
<p>Returns:
    auc : float
        Area under ROC for predicted classes</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">transform</span><span class="o">=</span><span class="kc">False</span>
<span class="n">iterators</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;regression&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="n">R2Score</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">),</span>
                            <span class="s1">&#39;RMSE&#39;</span><span class="p">:</span> <span class="n">MSEScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span><span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                            <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="n">MSEScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span><span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                            <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="n">MAEScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)},</span>
             <span class="s1">&#39;classification&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;MCC&#39;</span><span class="p">:</span> <span class="n">MatthewsCorrCoef</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">),</span>
                                <span class="s1">&#39;Se&#39;</span><span class="p">:</span> <span class="n">RecallScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                                <span class="s1">&#39;Sp&#39;</span><span class="p">:</span> <span class="n">RecallScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                                <span class="s1">&#39;Precision&#39;</span><span class="p">:</span> <span class="n">PrecisionScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                                <span class="s1">&#39;PR-AUC&#39;</span><span class="p">:</span> <span class="n">APScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">),</span>
                                <span class="s1">&#39;ROC-AUC&#39;</span><span class="p">:</span> <span class="n">ROCAucScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)},</span>
             <span class="s1">&#39;multi-class&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;MCC-Multi&#39;</span><span class="p">:</span> <span class="n">MatthewsCorrCoef</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">),</span>
                             <span class="s1">&#39;Se-Multi&#39;</span><span class="p">:</span> <span class="n">RecallScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">),</span>
                             <span class="s1">&#39;Sp-Multi&#39;</span><span class="p">:</span> <span class="n">RecallScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">),</span>
                             <span class="s1">&#39;Precision-Multi&#39;</span><span class="p">:</span> <span class="n">PrecisionScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">),</span>
                             <span class="s1">&#39;PR-AUC-Multi&#39;</span><span class="p">:</span> <span class="n">APScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">),</span>
                             <span class="s1">&#39;ROC-AUC-Multi&#39;</span><span class="p">:</span> <span class="n">ROCAucScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)}}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">iterators</span><span class="p">[</span><span class="s1">&#39;regression&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;R2&#39;: functools.partial(&lt;function r2_score at 0x7fae4093c8b0&gt;, sample_weight=None, multioutput=&#39;uniform_average&#39;),
 &#39;RMSE&#39;: functools.partial(&lt;function mean_squared_error at 0x7fae4093c550&gt;, sample_weight=None, multioutput=&#39;uniform_average&#39;, squared=False),
 &#39;MSE&#39;: functools.partial(&lt;function mean_squared_error at 0x7fae4093c550&gt;, sample_weight=None, multioutput=&#39;uniform_average&#39;, squared=True),
 &#39;MAE&#39;: functools.partial(&lt;function mean_absolute_error at 0x7fae40933670&gt;, sample_weight=None, multioutput=&#39;uniform_average&#39;)}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_multi_reg</span><span class="p">,</span> <span class="n">y_multi_reg</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_targets</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">X_multi_class</span><span class="p">,</span> <span class="n">y_multi_class</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">y_multi_class_bin</span> <span class="o">=</span> <span class="n">label_binarize</span><span class="p">(</span><span class="n">y_multi_class</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_multi_class</span><span class="p">))</span>
<span class="n">X_multi_label</span><span class="p">,</span> <span class="n">y_multi_label</span> <span class="o">=</span> <span class="n">make_multilabel_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Multiregression</strong></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>
<span class="n">Xtrain</span><span class="p">,</span><span class="n">Xtest</span><span class="p">,</span><span class="n">ytrain</span><span class="p">,</span><span class="n">ytest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_multi_reg</span><span class="p">,</span> <span class="n">y_multi_reg</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>

<span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>

<span class="n">iterators</span><span class="p">[</span><span class="s1">&#39;regression&#39;</span><span class="p">][</span><span class="s1">&#39;R2&#39;</span><span class="p">](</span><span class="n">ytest</span><span class="p">,</span> <span class="n">preds</span><span class="p">),</span> <span class="n">iterators</span><span class="p">[</span><span class="s1">&#39;regression&#39;</span><span class="p">][</span><span class="s1">&#39;RMSE&#39;</span><span class="p">](</span><span class="n">ytest</span><span class="p">,</span> <span class="n">preds</span><span class="p">),</span> <span class="n">iterators</span><span class="p">[</span><span class="s1">&#39;regression&#39;</span><span class="p">][</span><span class="s1">&#39;MSE&#39;</span><span class="p">](</span><span class="n">ytest</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.5427025983231036, 126.20481821744809, 16147.854816016916)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span><span class="c1">#RegressorChain(RandomForestRegressor())</span>
<span class="n">cv_k</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_multi_reg</span><span class="p">,</span> <span class="n">y_multi_reg</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;MAE&#39;</span><span class="p">:</span><span class="n">MAEScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                                                                     <span class="s1">&#39;RMSE&#39;</span><span class="p">:</span><span class="n">MSEScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                                                                     <span class="s1">&#39;MSE&#39;</span><span class="p">:</span><span class="n">MSEScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                                                                     <span class="s1">&#39;R2&#39;</span><span class="p">:</span><span class="n">R2Score</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="kc">True</span><span class="p">)})</span>
<span class="n">cv_k</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;fit_time&#39;: array([0.13002396, 0.12877083, 0.1232729 , 0.12998986, 0.13692403]),
 &#39;score_time&#39;: array([0.00560308, 0.00570536, 0.00596595, 0.00579786, 0.00602889]),
 &#39;test_MAE&#39;: array([ 83.1700755 ,  95.92275851, 104.62034272,  91.10423294,
         92.17806306]),
 &#39;test_RMSE&#39;: array([108.66873522, 123.23392384, 131.26824164, 112.98827644,
        123.00728827]),
 &#39;test_MSE&#39;: array([108.66873522, 123.23392384, 131.26824164, 112.98827644,
        123.00728827]),
 &#39;test_R2&#39;: array([0.49662594, 0.47525321, 0.50479834, 0.65515533, 0.50142682])}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Multiclass</strong></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_multi_class</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([1, 0, 2, 1, 2, 2, 1, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 1,
       1, 2, 1, 0, 0, 2, 2, 0, 0, 2, 0, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1,
       2, 2, 1, 2, 2, 1, 2, 0, 2, 2, 0, 0, 2, 1, 0, 0, 1, 1, 0, 1, 1, 0,
       2, 0, 2, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 0, 1, 2, 0,
       1, 0, 2, 0, 0, 0, 0, 1, 2, 1, 1, 1, 1, 2, 0, 2, 2, 0, 1, 2, 2, 1,
       2, 1, 0, 1, 2, 0, 1, 1, 1, 0, 0, 1, 0, 2, 2, 0, 1, 1, 2, 0, 2, 2,
       0, 0, 1, 1, 0, 1, 1, 2, 2, 2, 1, 0, 2, 0, 2, 1, 1, 1, 0, 1, 1, 0,
       1, 2, 1, 2, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1, 2, 0, 2, 2, 1, 1, 2, 2,
       0, 0, 2, 1, 0, 0, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1,
       0, 1])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="n">cv_k</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_multi_class</span><span class="p">,</span> <span class="n">y_multi_class</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;MCC&#39;</span><span class="p">:</span><span class="n">MatthewsCorrCoef</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                                                                         <span class="s1">&#39;Fbeta&#39;</span><span class="p">:</span><span class="n">FBetaScore</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)})</span>
<span class="n">cv_k</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;fit_time&#39;: array([0.10075498, 0.09242988, 0.09186816, 0.09466481, 0.11119604]),
 &#39;score_time&#39;: array([0.00876403, 0.00896502, 0.00756669, 0.00905013, 0.00908279]),
 &#39;test_MCC&#39;: array([0.06749647, 0.2160412 , 0.21823046, 0.17976054, 0.25104   ]),
 &#39;test_Fbeta&#39;: array([0.37735871, 0.4777751 , 0.47784109, 0.46920203, 0.49186523])}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Multilabel</strong></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_multi_class_bin</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[0, 1, 0],
       [1, 0, 0],
       [0, 0, 1],
       [0, 1, 0],
       [0, 0, 1],
       [0, 0, 1],
       [0, 1, 0],
       [1, 0, 0],
       [1, 0, 0],
       [0, 0, 1],
       [1, 0, 0],
       [0, 0, 1],
       [1, 0, 0],
       [1, 0, 0],
       [1, 0, 0],
       [1, 0, 0],
       [0, 0, 1],
       [1, 0, 0],
       [0, 0, 1],
       [0, 0, 1],
       [1, 0, 0],
       [0, 1, 0],
       [0, 1, 0],
       [0, 0, 1],
       [0, 1, 0],
       [1, 0, 0],
       [1, 0, 0],
       [0, 0, 1],
       [0, 0, 1],
       [1, 0, 0],
       [1, 0, 0],
       [0, 0, 1],
       [1, 0, 0],
       [0, 0, 1],
       [0, 0, 1],
       [0, 1, 0],
       [0, 1, 0],
       [0, 0, 1],
       [0, 0, 1],
       [0, 1, 0],
       [0, 0, 1],
       [0, 0, 1],
       [0, 0, 1],
       [0, 1, 0],
       [0, 0, 1],
       [0, 0, 1],
       [0, 1, 0],
       [0, 0, 1],
       [0, 0, 1],
       [0, 1, 0],
       [0, 0, 1],
       [1, 0, 0],
       [0, 0, 1],
       [0, 0, 1],
       [1, 0, 0],
       [1, 0, 0],
       [0, 0, 1],
       [0, 1, 0],
       [1, 0, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 1, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 1, 0],
       [1, 0, 0],
       [0, 0, 1],
       [1, 0, 0],
       [0, 0, 1],
       [0, 1, 0],
       [0, 0, 1],
       [1, 0, 0],
       [1, 0, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 0, 0],
       [1, 0, 0],
       [1, 0, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [0, 1, 0],
       [0, 1, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 0, 0],
       [0, 1, 0],
       [1, 0, 0],
       [0, 0, 1],
       [1, 0, 0],
       [1, 0, 0],
       [1, 0, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [0, 1, 0],
       [0, 1, 0],
       [0, 1, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 0, 0],
       [0, 0, 1],
       [0, 0, 1],
       [1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [0, 0, 1],
       [0, 1, 0],
       [0, 0, 1],
       [0, 1, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 0, 0],
       [0, 1, 0],
       [0, 1, 0],
       [0, 1, 0],
       [1, 0, 0],
       [1, 0, 0],
       [0, 1, 0],
       [1, 0, 0],
       [0, 0, 1],
       [0, 0, 1],
       [1, 0, 0],
       [0, 1, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 0, 0],
       [0, 0, 1],
       [0, 0, 1],
       [1, 0, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 1, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 1, 0],
       [0, 0, 1],
       [0, 0, 1],
       [0, 0, 1],
       [0, 1, 0],
       [1, 0, 0],
       [0, 0, 1],
       [1, 0, 0],
       [0, 0, 1],
       [0, 1, 0],
       [0, 1, 0],
       [0, 1, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 1, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [0, 1, 0],
       [0, 0, 1],
       [1, 0, 0],
       [1, 0, 0],
       [1, 0, 0],
       [1, 0, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [0, 1, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 0, 0],
       [0, 0, 1],
       [0, 0, 1],
       [0, 1, 0],
       [0, 1, 0],
       [0, 0, 1],
       [0, 0, 1],
       [1, 0, 0],
       [1, 0, 0],
       [0, 0, 1],
       [0, 1, 0],
       [1, 0, 0],
       [1, 0, 0],
       [0, 0, 1],
       [0, 1, 0],
       [0, 0, 1],
       [0, 1, 0],
       [0, 0, 1],
       [0, 0, 1],
       [0, 1, 0],
       [0, 0, 1],
       [0, 0, 1],
       [0, 1, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 1, 0],
       [0, 1, 0],
       [0, 1, 0],
       [0, 1, 0],
       [1, 0, 0],
       [0, 1, 0]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">ClassifierChain</span><span class="p">(</span><span class="n">RandomForestClassifier</span><span class="p">())</span>
<span class="n">cv_k</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_multi_label</span><span class="p">,</span> <span class="n">y_multi_label</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;MCC&#39;</span><span class="p">:</span><span class="n">MatthewsCorrCoef</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="kc">True</span><span class="p">)})</span>
<span class="n">cv_k</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py&#34;, line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py&#34;, line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py&#34;, line 264, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py&#34;, line 895, in matthews_corrcoef
    raise ValueError(&#34;%s is not supported&#34; % y_type)
ValueError: multilabel-indicator is not supported

  warnings.warn(
/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py&#34;, line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py&#34;, line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py&#34;, line 264, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py&#34;, line 895, in matthews_corrcoef
    raise ValueError(&#34;%s is not supported&#34; % y_type)
ValueError: multilabel-indicator is not supported

  warnings.warn(
/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py&#34;, line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py&#34;, line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py&#34;, line 264, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py&#34;, line 895, in matthews_corrcoef
    raise ValueError(&#34;%s is not supported&#34; % y_type)
ValueError: multilabel-indicator is not supported

  warnings.warn(
/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py&#34;, line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py&#34;, line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py&#34;, line 264, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py&#34;, line 895, in matthews_corrcoef
    raise ValueError(&#34;%s is not supported&#34; % y_type)
ValueError: multilabel-indicator is not supported

  warnings.warn(
/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py&#34;, line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py&#34;, line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py&#34;, line 264, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File &#34;/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py&#34;, line 895, in matthews_corrcoef
    raise ValueError(&#34;%s is not supported&#34; % y_type)
ValueError: multilabel-indicator is not supported

  warnings.warn(
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;fit_time&#39;: array([0.10971403, 0.10090184, 0.09475207, 0.09986997, 0.09748006]),
 &#39;score_time&#39;: array([0.01379085, 0.01196384, 0.01571298, 0.012218  , 0.01511884]),
 &#39;test_MCC&#39;: array([nan, nan, nan, nan, nan])}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_multi_label</span><span class="p">,</span><span class="n">y_multi_label</span><span class="p">)</span>
<span class="n">probas</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_multi_label</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probas</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[0, 1, 1, 0, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 0, 0],
       [1, 1, 0, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 1, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 0, 0],
       [1, 0, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 1, 1],
       [0, 0, 1, 1, 0],
       [0, 1, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 0, 0],
       [0, 1, 1, 1, 1],
       [0, 1, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 1, 1, 1],
       [0, 0, 1, 0, 0],
       [0, 1, 1, 1, 1],
       [1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 1, 0, 1, 0],
       [1, 0, 0, 1, 0],
       [0, 1, 1, 1, 0],
       [1, 1, 1, 1, 1],
       [1, 1, 1, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 0, 1],
       [0, 0, 0, 0, 0],
       [1, 1, 1, 1, 1],
       [1, 0, 0, 0, 0],
       [0, 0, 0, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 0, 1, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 1, 1, 1, 1],
       [0, 0, 1, 1, 0],
       [0, 1, 0, 0, 0],
       [0, 1, 1, 1, 1],
       [1, 1, 1, 1, 1],
       [0, 0, 1, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 1, 1, 1, 1],
       [0, 1, 1, 1, 0],
       [0, 1, 1, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 0, 0],
       [1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 1, 1, 0, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 0, 0, 0],
       [1, 1, 1, 1, 1],
       [0, 0, 1, 0, 0],
       [1, 1, 1, 1, 0],
       [1, 0, 1, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 0, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 0, 1, 0, 0],
       [1, 1, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 1, 1, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 1, 0, 0],
       [0, 1, 1, 1, 1],
       [0, 0, 1, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 1, 0, 0, 0],
       [0, 1, 0, 0, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 0, 1, 0, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 1, 1, 1],
       [0, 0, 1, 1, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 1],
       [0, 0, 1, 0, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 1, 0, 0],
       [1, 1, 1, 1, 1],
       [1, 0, 0, 1, 0],
       [0, 1, 1, 0, 0],
       [0, 0, 1, 1, 1],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 0, 1],
       [0, 1, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 1, 0, 1, 0],
       [0, 1, 0, 1, 0],
       [0, 1, 1, 0, 0],
       [0, 0, 0, 1, 0],
       [1, 0, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [1, 1, 1, 1, 1],
       [1, 1, 1, 1, 0],
       [0, 1, 1, 1, 1],
       [0, 0, 0, 0, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 0, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 0, 0, 0],
       [0, 0, 1, 0, 1],
       [0, 1, 1, 1, 0],
       [0, 0, 1, 1, 1],
       [0, 1, 1, 0, 0],
       [0, 0, 1, 0, 0],
       [0, 0, 0, 1, 0],
       [0, 1, 1, 1, 0],
       [1, 1, 1, 1, 1],
       [0, 0, 0, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 0, 1, 0],
       [0, 1, 0, 0, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 1, 1, 0],
       [1, 1, 1, 1, 0],
       [0, 1, 1, 1, 1],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 1, 1],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1],
       [0, 1, 1, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0],
       [1, 1, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [1, 1, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 0, 0, 1, 0],
       [1, 0, 1, 0, 0],
       [0, 0, 0, 1, 0]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_multi_label</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[0, 1, 1, 0, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 0, 0],
       [1, 1, 0, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 1, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 0, 0],
       [1, 0, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 1, 1],
       [0, 0, 1, 1, 0],
       [0, 1, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 0, 0],
       [0, 1, 1, 1, 1],
       [0, 1, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 1, 1, 1],
       [0, 0, 1, 0, 0],
       [0, 1, 1, 1, 1],
       [1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 1, 0, 1, 0],
       [1, 0, 0, 1, 0],
       [0, 1, 1, 1, 0],
       [1, 1, 1, 1, 1],
       [1, 1, 1, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 0, 1],
       [0, 0, 0, 0, 0],
       [1, 1, 1, 1, 1],
       [1, 0, 0, 0, 0],
       [0, 0, 0, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 0, 1, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 1, 1, 1, 1],
       [0, 0, 1, 1, 0],
       [0, 1, 0, 0, 0],
       [0, 1, 1, 1, 1],
       [1, 1, 1, 1, 1],
       [0, 0, 1, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 1, 1, 1, 1],
       [0, 1, 1, 1, 0],
       [0, 1, 1, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 0, 0],
       [1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 1, 1, 0, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 0, 0, 0],
       [1, 1, 1, 1, 1],
       [0, 0, 1, 0, 0],
       [1, 1, 1, 1, 0],
       [1, 0, 1, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 0, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 0, 1, 0, 0],
       [1, 1, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 1, 1, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 1, 0, 0],
       [0, 1, 1, 1, 1],
       [0, 0, 1, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 1, 0, 0, 0],
       [0, 1, 0, 0, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 0, 1, 0, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 1, 1, 1],
       [0, 0, 1, 1, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 1],
       [0, 0, 1, 0, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 1, 0, 0],
       [1, 1, 1, 1, 1],
       [1, 0, 0, 1, 0],
       [0, 1, 1, 0, 0],
       [0, 0, 1, 1, 1],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 0, 1],
       [0, 1, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 1, 0, 0],
       [0, 1, 0, 1, 0],
       [0, 1, 0, 1, 0],
       [0, 1, 1, 0, 0],
       [0, 0, 0, 1, 0],
       [1, 0, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [1, 1, 1, 1, 1],
       [1, 1, 1, 1, 0],
       [0, 1, 1, 1, 1],
       [0, 0, 0, 0, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 0, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 0, 0, 0],
       [0, 0, 1, 0, 1],
       [0, 1, 1, 1, 0],
       [0, 0, 1, 1, 1],
       [0, 1, 1, 0, 0],
       [0, 0, 1, 0, 0],
       [0, 0, 0, 1, 0],
       [0, 1, 1, 1, 0],
       [1, 1, 1, 1, 1],
       [0, 0, 0, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 0, 1, 0],
       [0, 1, 0, 0, 0],
       [0, 0, 0, 0, 0],
       [0, 1, 1, 1, 0],
       [0, 1, 1, 1, 0],
       [1, 1, 1, 1, 0],
       [0, 1, 1, 1, 1],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 0, 1, 1, 0],
       [0, 1, 0, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 1, 1],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1],
       [0, 1, 1, 1, 0],
       [0, 0, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0],
       [1, 1, 1, 1, 0],
       [0, 0, 0, 0, 0],
       [1, 1, 1, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0],
       [0, 0, 0, 1, 0],
       [1, 0, 1, 0, 0],
       [0, 0, 0, 1, 0]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">FBetaScore</span><span class="p">()(</span><span class="n">y_multi_label</span><span class="p">,</span> <span class="n">probas</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1.0</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">RecallScore</span><span class="p">(</span><span class="n">y_multi_label</span><span class="p">,</span> <span class="n">probas</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>functools.partial(&lt;function recall_score at 0x7fae40906af0&gt;, average=&#39;macro&#39;, pos_label=1, sample_weight=None)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">g2</span> <span class="o">=</span> <span class="n">APScore</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
<span class="n">g1</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">g1</span> <span class="o">==</span> <span class="n">g2</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">g2</span> <span class="o">=</span> <span class="n">ROCAucScore</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="n">g1</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">g1</span> <span class="o">==</span> <span class="n">g2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">avg</span> <span class="o">=</span> <span class="s1">&#39;binary&#39;</span>
<span class="n">g2</span> <span class="o">=</span> <span class="n">RecallScore</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_scores</span><span class="o">&gt;=</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">transform</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="n">avg</span><span class="p">)</span>
<span class="n">g1</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_scores</span><span class="o">&gt;=</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="n">average</span><span class="o">=</span><span class="n">avg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">g1</span> <span class="o">==</span> <span class="n">g2</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">avg</span> <span class="o">=</span> <span class="s1">&#39;micro&#39;</span>
<span class="n">g2</span> <span class="o">=</span> <span class="n">PrecisionScore</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_scores</span><span class="o">&gt;=</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">transform</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="n">avg</span><span class="p">)</span>
<span class="n">g1</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_scores</span><span class="o">&gt;=</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="n">average</span><span class="o">=</span><span class="n">avg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">g1</span> <span class="o">==</span> <span class="n">g2</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">avg</span> <span class="o">=</span> <span class="s1">&#39;micro&#39;</span>
<span class="n">g2</span> <span class="o">=</span> <span class="n">BalancedAccuracyScore</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_scores</span><span class="o">&gt;=</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">transform</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">g1</span> <span class="o">=</span> <span class="n">balanced_accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_scores</span><span class="o">&gt;=</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">g1</span> <span class="o">==</span> <span class="n">g2</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

